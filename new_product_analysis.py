import streamlit as st
import pandas as pd
import json
from datetime import datetime
from io import BytesIO
from pathlib import Path
from typing import Optional, Dict, Any, Tuple
import logging
import warnings
import re
import pymysql
from sqlalchemy import create_engine

warnings.filterwarnings('ignore', category=UserWarning, module='openpyxl')
warnings.filterwarnings('ignore', category=UserWarning, module='pandas.io.sql')

# --- å¸¸é‡å®šä¹‰ (Constants) ---
CONFIG_FILE = Path("config.json")

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# --- æ–‡ä»¶å¤„ç†ç±» (File Processing) ---
class FileProcessor:
    """æ–‡ä»¶å¤„ç†ç±»ï¼Œè´Ÿè´£Excelæ–‡ä»¶çš„è¯»å–å’Œä¿å­˜"""
    
    @staticmethod
    def read_excel_safe(file_path_or_buffer) -> pd.DataFrame:
        """
        å®‰å…¨çš„Excelè¯»å–æ–¹æ³•ï¼Œå…ˆå°†æ–‡ä»¶ä¿å­˜ä¸ºä¸´æ—¶æ–‡ä»¶ï¼Œç„¶åä»ä¸´æ—¶æ–‡ä»¶è¯»å–
        """
        import io
        import tempfile
        import os

        # è·å–æ–‡ä»¶å†…å®¹åˆ°BytesIO
        if hasattr(file_path_or_buffer, 'getvalue'):
            original_buffer = io.BytesIO(file_path_or_buffer.getvalue())
            file_name = file_path_or_buffer.name
        else:
            with open(file_path_or_buffer, 'rb') as f:
                original_buffer = io.BytesIO(f.read())
            file_name = str(file_path_or_buffer)

        # åˆ›å»ºä¸´æ—¶æ–‡ä»¶
        with tempfile.NamedTemporaryFile(delete=False, suffix='.xlsx') as temp_file:
            temp_file_path = temp_file.name
            original_buffer.seek(0)
            temp_file.write(original_buffer.read())

        try:
            # å°è¯•ä½¿ç”¨ä¸åŒå¼•æ“è¯»å–ä¸´æ—¶æ–‡ä»¶
            engines = ['openpyxl', 'xlrd']
            for engine in engines:
                try:
                    return pd.read_excel(temp_file_path, engine=engine)
                except Exception as e:
                    logger.warning(f"è¯»å–å¤±è´¥ (å¼•æ“ {engine}): {str(e)}")
                    continue

            raise ValueError(f"æ— æ³•è¯»å–æ–‡ä»¶ {file_name}ã€‚è¯·ç¡®è®¤æ–‡ä»¶æ ¼å¼æ­£ç¡®ã€‚")
            
        finally:
            # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
            try:
                os.unlink(temp_file_path)
            except Exception as cleanup_e:
                logger.warning(f"ä¸´æ—¶æ–‡ä»¶æ¸…ç†å¤±è´¥: {str(cleanup_e)}")

# --- æ–‡ä»¶ä¸Šä¼ ç»„ä»¶ç±» (File Upload Widget) ---
class FileUploadWidget:
    """æ–‡ä»¶ä¸Šä¼ ç»„ä»¶ç±»ï¼Œæä¾›æ›´å¥½çš„çŠ¶æ€ç®¡ç†"""
    
    def __init__(self, config_manager=None):
        # ä¸ºäº†ä¿æŒå…¼å®¹æ€§ï¼Œå³ä½¿æ²¡æœ‰é…ç½®ç®¡ç†å™¨ä¹Ÿèƒ½å·¥ä½œ
        self.config_manager = config_manager
    
    def render(self, label: str, session_state_key: str) -> Optional[pd.DataFrame]:
        """
        æ¸²æŸ“æ–‡ä»¶ä¸Šä¼ ç»„ä»¶å¹¶è¿”å›åŠ è½½çš„æ•°æ®
        
        Args:
            label: ä¸Šä¼ ç»„ä»¶çš„æ ‡ç­¾
            session_state_key: session stateä¸­ä¿å­˜æ•°æ®çš„é”®
            
        Returns:
            åŠ è½½çš„DataFrameæˆ–None
        """
        # åˆå§‹åŒ–session state
        if session_state_key not in st.session_state:
            st.session_state[session_state_key] = None
        
        # åˆ›å»ºå”¯ä¸€çš„uploader key
        uploader_key = f"uploader_{session_state_key}_{hash(label)}"
        
        # è·Ÿè¸ªæ–‡ä»¶çŠ¶æ€å˜åŒ–
        file_state_key = f"file_state_{session_state_key}"
        if file_state_key not in st.session_state:
            st.session_state[file_state_key] = None
        
        # æ–‡ä»¶ä¸Šä¼ å™¨
        uploaded_file = st.file_uploader(
            label, 
            type=['xlsx', 'xls'], 
            key=uploader_key,
            help="æ”¯æŒ.xlsxå’Œ.xlsæ ¼å¼çš„Excelæ–‡ä»¶"
        )
        
        # å¤„ç†æ–‡ä»¶ä¸Šä¼ æˆ–åˆ é™¤
        if uploaded_file is not None:
            # æ–‡ä»¶è¢«ä¸Šä¼ 
            st.session_state[file_state_key] = uploaded_file.name
            return self._handle_file_upload(uploaded_file, session_state_key)
        else:
            # æ£€æŸ¥æ˜¯å¦æ–‡ä»¶è¢«åˆ é™¤
            if st.session_state.get(file_state_key) is not None and st.session_state.get(session_state_key) is not None:
                st.session_state[session_state_key] = None
                st.session_state[file_state_key] = None
        
        # æ·»åŠ æ‰‹åŠ¨æ–‡ä»¶è·¯å¾„è¾“å…¥ä½œä¸ºå¤‡é€‰æ–¹æ¡ˆ
        with st.expander("ğŸ”§ é«˜çº§é€‰é¡¹"):
            manual_path = st.text_input(
                "æ‰‹åŠ¨æŒ‡å®šæ–‡ä»¶è·¯å¾„:",
                key=f"manual_path_{session_state_key}",
                help="ä¾‹å¦‚: C:/Users/ç”¨æˆ·å/Desktop/æ–‡ä»¶.xlsx"
            )
            
            if st.button("ğŸ“ ä»è·¯å¾„åŠ è½½", key=f"load_manual_{session_state_key}"):
                if manual_path and Path(manual_path).exists():
                    try:
                        with st.spinner("æ­£åœ¨è¯»å–æ–‡ä»¶..."):
                            data = FileProcessor.read_excel_safe(Path(manual_path))
                        
                        st.session_state[session_state_key] = data
                        st.session_state[file_state_key] = Path(manual_path).name
                        
                        st.success(f"âœ… æˆåŠŸåŠ è½½: {Path(manual_path).name} ({len(data)} è¡Œ)")
                        return data
                        
                    except Exception as e:
                        st.error(f"âŒ è¯»å–å¤±è´¥: {str(e)}")
                        return None
                elif manual_path:
                    st.error("âŒ æ–‡ä»¶è·¯å¾„ä¸å­˜åœ¨")
                else:
                    st.warning("âš ï¸ è¯·è¾“å…¥æœ‰æ•ˆè·¯å¾„")
        
        return st.session_state.get(session_state_key)
    
    def _handle_file_upload(self, uploaded_file, session_state_key: str) -> pd.DataFrame:
        """å¤„ç†æ–‡ä»¶ä¸Šä¼ """
        try:
            # æ£€æŸ¥æ–‡ä»¶å¤§å°
            file_size = len(uploaded_file.getvalue())
            if file_size > 50 * 1024 * 1024:  # 50MBé™åˆ¶
                st.warning("âš ï¸ æ–‡ä»¶è¾ƒå¤§ï¼Œè¯»å–å¯èƒ½éœ€è¦ä¸€äº›æ—¶é—´...")
            
            # ä½¿ç”¨ä¸´æ—¶æ–‡ä»¶æ–¹å¼è¯»å–
            with st.spinner(f"æ­£åœ¨è¯»å–æ–‡ä»¶ {uploaded_file.name}..."):
                data = FileProcessor.read_excel_safe(uploaded_file)
            
            # æ›´æ–°session state
            st.session_state[session_state_key] = data
            
            st.success(f"âœ… æˆåŠŸåŠ è½½æ–‡ä»¶: {uploaded_file.name} ({len(data)} è¡Œ, {len(data.columns)} åˆ—)")
            return data
            
        except Exception as e:
            st.error(f"âŒ è¯»å–å¤±è´¥: {uploaded_file.name}")
            st.info("ğŸ’¡ å»ºè®®ï¼šæ£€æŸ¥æ–‡ä»¶æ ¼å¼æˆ–ä½¿ç”¨é«˜çº§é€‰é¡¹")
            
            st.session_state[session_state_key] = None
            return None

# --- SQLå¤„ç†å™¨ç±» ---
class SQLProcessor:
    """SQLå¤„ç†å™¨ç±»ï¼Œè´Ÿè´£æ‰§è¡ŒSQLæŸ¥è¯¢"""
    
    @staticmethod
    def read_sql_file(file_path: Path) -> str:
        """è¯»å–SQLæ–‡ä»¶å†…å®¹"""
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                return f.read()
        except Exception as e:
            logger.error(f"è¯»å–SQLæ–‡ä»¶å¤±è´¥: {e}")
            raise ValueError(f"è¯»å–SQLæ–‡ä»¶å¤±è´¥: {str(e)}")
    
    @staticmethod
    def extract_sql_from_file(file_path: Path) -> str:
        """ä»SQLæ–‡ä»¶ä¸­æå–æŸ¥è¯¢è¯­å¥"""
        sql_content = SQLProcessor.read_sql_file(file_path)
        # ç§»é™¤æ³¨é‡Š
        sql_content = re.sub(r'--.*$', '', sql_content, flags=re.MULTILINE)
        sql_content = re.sub(r'/\*.*?\*/', '', sql_content, flags=re.DOTALL)
        return sql_content.strip()
    
    @staticmethod
    def execute_sql_query(sql_query: str) -> pd.DataFrame:
        """æ‰§è¡ŒSQLæŸ¥è¯¢å¹¶è¿”å›ç»“æœï¼ˆè¿æ¥MySQLæ•°æ®åº“ï¼‰"""
        # æ³¨æ„ï¼šè¿™é‡Œä½¿ç”¨äº†éœ€æ±‚æ–‡æ¡£ä¸­æåˆ°çš„é»˜è®¤SQLæ–‡ä»¶
        default_sql_file = Path("å¯¹æ ‡å“.sql")
        if default_sql_file.exists():
            try:
                with open(default_sql_file, 'r', encoding='utf-8') as f:
                    sql_query = f.read()
            except Exception as e:
                logger.error(f"è¯»å–é»˜è®¤SQLæ–‡ä»¶å¤±è´¥: {e}")
                st.error(f"è¯»å–é»˜è®¤SQLæ–‡ä»¶å¤±è´¥: {str(e)}")
                return pd.DataFrame()
        
        host = "10.243.0.221"      # æ•°æ®åº“åœ°å€
        port = 3306                # ç«¯å£å·
        user = "xinpin"     # ç”¨æˆ·å
        password = "xinpin" # å¯†ç 
        database = "new_goods_manage" # æ•°æ®åº“å

        try:
            # å»ºç«‹æ•°æ®åº“è¿æ¥
            conn = pymysql.connect(
                host=host,
                port=port,
                user=user,
                password=password,
                database=database,
                charset='utf8mb4'
            )
            # æ‰§è¡ŒSQLæŸ¥è¯¢
            engine = create_engine(
                "mysql+pymysql://xinpin:xinpin@10.243.0.221:3306/new_goods_manage?charset=utf8mb4"
            )
            df = pd.read_sql(sql_query, engine)
            conn.close()
            return df
        except Exception as e:
            logger.error(f"æ‰§è¡ŒSQLæŸ¥è¯¢å¤±è´¥: {e}")
            st.error(f"æ‰§è¡ŒSQLæŸ¥è¯¢å¤±è´¥: {str(e)}")
            return pd.DataFrame()

# --- æ˜ å°„å¤„ç†ç±» (Mapping Processor) ---
class MappingProcessor:
    """æ˜ å°„å¤„ç†ç±»ï¼Œè´Ÿè´£å­—æ®µæ˜ å°„é€»è¾‘"""
    
    @staticmethod
    def run_mapping(map_df: pd.DataFrame, source_df: pd.DataFrame, source_type: str = 'table2') -> pd.DataFrame:
        """æ‰§è¡Œå­—æ®µæ˜ å°„
        Args:
            map_df: æ˜ å°„å…³ç³»è¡¨ï¼ˆåŒ…å«ä¸‰åˆ—ï¼šç›®æ ‡å­—æ®µåã€table2å­—æ®µåã€table3å­—æ®µåï¼‰
            source_df: æºæ•°æ®è¡¨
            source_type: æºæ•°æ®ç±»å‹ ('table2' æˆ– 'table3')
        """
        if map_df.empty or source_df.empty:
            raise ValueError("æ˜ å°„è¡¨æˆ–æºæ•°æ®ä¸ºç©º")
        
        # æå–æ˜ å°„å…³ç³»
        # æ ¹æ®source_typeé€‰æ‹©å¯¹åº”çš„æ˜ å°„åˆ—
        if source_type == 'table2':
            # table2å­—æ®µååœ¨ç¬¬äºŒåˆ—ï¼ˆç´¢å¼•1ï¼‰
            source_field_col = 1
        elif source_type == 'table3':
            # table3å­—æ®µååœ¨ç¬¬ä¸‰åˆ—ï¼ˆç´¢å¼•2ï¼‰
            source_field_col = 2
        else:
            raise ValueError("source_type å¿…é¡»æ˜¯ 'table2' æˆ– 'table3'")
        
        map_df_clean = map_df.dropna(how='all') # ç§»é™¤ NaN
        # ç›®æ ‡å­—æ®µååœ¨ç¬¬ä¸€åˆ—ï¼ˆç´¢å¼•0ï¼‰
        main_fields = map_df_clean.iloc[:, 0].tolist()
        # æ ¹æ®source_typeé€‰æ‹©æºå­—æ®µåˆ—
        source_fields = map_df_clean.iloc[:, source_field_col].tolist()
        
        
        # æ„å»ºæ˜ å°„å­—å…¸ {æºå­—æ®µ: ç›®æ ‡å­—æ®µ}
        field_map = {}
        for target_field, source_field in zip(main_fields, source_fields):
            # åªå¤„ç†éç©ºä¸”æœ‰æ•ˆçš„æ˜ å°„
            if pd.notna(source_field) and source_field != '' and pd.notna(target_field):
                field_map[str(source_field)] = str(target_field)
        
        
        # ä» source_df ä¸­é€‰å–å¹¶é‡å‘½åå­˜åœ¨çš„åˆ—
        available_cols = [col for col in field_map if col in source_df.columns]
        result_df = source_df[available_cols].rename(columns=field_map)
        
        # æ·»åŠ ç¼ºå¤±çš„ç›®æ ‡åˆ—ï¼Œå¹¶å¡«å……ä¸ºç©ºå­—ç¬¦ä¸²ï¼ˆä»…æ·»åŠ åœ¨æ˜ å°„æ¸…å•ä¸­å‡ºç°è¿‡çš„ç›®æ ‡å­—æ®µï¼‰
        existing_cols = set(result_df.columns)
        for col in main_fields:
            if col not in existing_cols:
                result_df[col] = ''
        
        # é‡æ–°æ’åºåˆ—ä»¥åŒ¹é…ç›®æ ‡å­—æ®µé¡ºåº
        result_df = result_df[main_fields]
        
        return result_df

# --- æ•°æ®ç­›é€‰å¤„ç†å™¨ ---
class DataFilterProcessor:
    """æ•°æ®ç­›é€‰å¤„ç†å™¨ï¼Œè´Ÿè´£å¯¹æ ‡å“æ•°æ®çš„ç­›é€‰"""
    
    @staticmethod
    def filter_benchmark_data(benchmark_df: pd.DataFrame, scm_df: pd.DataFrame) -> pd.DataFrame:
        """æ ¹æ®SCMæ•°æ®ç­›é€‰å¯¹æ ‡å“æ•°æ®"""
        if benchmark_df.empty or scm_df.empty:
            raise ValueError("å¯¹æ ‡å“æ•°æ®æˆ–SCMæ•°æ®ä¸ºç©º")
        
        # è·å–SCMæ•°æ®ä¸­çš„é€šç”¨åå’Œä¸‰çº§å¤§ç±»
        # æ ¹æ®éœ€æ±‚æ–‡æ¡£ï¼ŒSCMæ•°æ®ä¸­å¯¹åº”çš„åˆ—ä¸º"é€šç”¨å"å’Œ"ç­–ç•¥åˆ†ç±»"
        scm_common_names = set(scm_df.get('é€šç”¨å', pd.Series(dtype=object)).dropna().astype(str).unique())
        scm_category3_names = set(scm_df.get('ç­–ç•¥åˆ†ç±»', pd.Series(dtype=object)).dropna().astype(str).unique())
        
        # ç­›é€‰å¯¹æ ‡å“æ•°æ®
        # å¯¹æ ‡å“æ•°æ®ä¸­å¯¹åº”çš„åˆ—ä¸º"é€šç”¨å"å’Œ"ä¸‰çº§ç­–ç•¥åˆ†ç±»"
        filtered_df = benchmark_df[
            (benchmark_df['é€šç”¨å'].astype(str).isin(scm_common_names)) |
            (benchmark_df['ä¸‰çº§ç­–ç•¥åˆ†ç±»'].astype(str).isin(scm_category3_names))
        ]
        
        return filtered_df

# --- æ•°æ®åˆå¹¶å¤„ç†å™¨ ---
class DataMerger:
    """æ•°æ®åˆå¹¶å¤„ç†å™¨ï¼Œè´Ÿè´£åˆå¹¶æ˜ å°„åçš„æ•°æ®å¹¶æ’åº"""
    
    @staticmethod
    def merge_and_sort_data(map_scm_df: pd.DataFrame, map_benchmark_df: pd.DataFrame) -> pd.DataFrame:
        """åˆå¹¶æ˜ å°„åçš„æ•°æ®å¹¶æŒ‰æŒ‡å®šè§„åˆ™æ’åº"""
        # åˆ›å»ºå‰¯æœ¬ä»¥é¿å…ä¿®æ”¹åŸå§‹æ•°æ®
        map_scm_df = map_scm_df.copy()
        map_benchmark_df = map_benchmark_df.copy()
        
        if map_scm_df.empty and map_benchmark_df.empty:
            raise ValueError("ä¸¤ä¸ªæ˜ å°„åçš„æ•°æ®è¡¨éƒ½ä¸ºç©º")
        
        # åˆå¹¶æ•°æ®
        if not map_scm_df.empty and not map_benchmark_df.empty:
            # æ·»åŠ æ ‡è¯†åˆ—åŒºåˆ†æ•°æ®æ¥æº
            map_scm_df['__source__'] = 'scm'
            map_benchmark_df['__source__'] = 'benchmark'
            
            # åˆå¹¶æ•°æ®
            merged_df = pd.concat([map_scm_df, map_benchmark_df], ignore_index=True)
            
            # æŒ‰ä¸‰çº§å¤§ç±»åˆ†ç»„æ’åº
            if 'ä¸‰çº§å¤§ç±»' in merged_df.columns:
                # å¯¹benchmarkæ•°æ®æŒ‰é”€å”®é¢é™åºæ’åº
                benchmark_part = merged_df[merged_df['__source__'] == 'benchmark'].copy()
                if 'è¿‘90å¤©æœˆå‡é”€å”®é‡‘é¢' in benchmark_part.columns:
                    benchmark_part = benchmark_part.sort_values('è¿‘90å¤©æœˆå‡é”€å”®é‡‘é¢', ascending=False)
                
                # SCMæ•°æ®åœ¨å‰ï¼Œbenchmarkæ•°æ®åœ¨å
                scm_part = merged_df[merged_df['__source__'] == 'scm']
                
                # é‡æ–°ç»„åˆæ•°æ®
                result_parts = []
                # æŒ‰ä¸‰çº§å¤§ç±»åˆ†ç»„å¤„ç†
                for category in merged_df['ä¸‰çº§å¤§ç±»'].dropna().unique():
                    scm_category = scm_part[scm_part['ä¸‰çº§å¤§ç±»'] == category]
                    benchmark_category = benchmark_part[benchmark_part['ä¸‰çº§å¤§ç±»'] == category]
                    if not scm_category.empty or not benchmark_category.empty:
                        result_parts.append(pd.concat([scm_category, benchmark_category], ignore_index=True))
                
                # å¤„ç†æ²¡æœ‰ä¸‰çº§å¤§ç±»çš„æ•°æ®
                scm_no_category = scm_part[scm_part['ä¸‰çº§å¤§ç±»'].isna()]
                benchmark_no_category = benchmark_part[benchmark_part['ä¸‰çº§å¤§ç±»'].isna()]
                if not scm_no_category.empty or not benchmark_no_category.empty:
                    result_parts.append(pd.concat([scm_no_category, benchmark_no_category], ignore_index=True))
                
                # åˆå¹¶æ‰€æœ‰éƒ¨åˆ†
                if result_parts:
                    final_df = pd.concat(result_parts, ignore_index=True)
                else:
                    final_df = merged_df
            else:
                # å¦‚æœæ²¡æœ‰ä¸‰çº§å¤§ç±»å­—æ®µï¼Œç›´æ¥åˆå¹¶
                final_df = merged_df
            
            # åˆ é™¤æ ‡è¯†åˆ—
            final_df = final_df.drop(columns=['__source__'])
        elif not map_scm_df.empty:
            final_df = map_scm_df
        else:
            final_df = map_benchmark_df
        
        return final_df

# --- ç»“æœå¯¼å‡ºç±» (Result Exporter) ---
class ResultExporter:
    """ç»“æœå¯¼å‡ºç±»ï¼Œè´Ÿè´£ç”Ÿæˆå’Œä¸‹è½½ç»“æœæ–‡ä»¶"""
    
    @staticmethod
    def export_to_excel(df: pd.DataFrame, scm_indices: list) -> Tuple[BytesIO, str]:
        """å¯¼å‡ºDataFrameåˆ°Excelæ ¼å¼ï¼Œå¹¶å¯¹SCMæ•°æ®è¡Œæ·»åŠ é»„è‰²èƒŒæ™¯"""
        output = BytesIO()
        
        # åˆ›å»ºExcelå†™å…¥å™¨
        with pd.ExcelWriter(output, engine='openpyxl') as writer:
            df.to_excel(writer, index=False, sheet_name='ç›®æ ‡è¡¨')
            
            # è·å–å·¥ä½œè¡¨
            worksheet = writer.sheets['ç›®æ ‡è¡¨']
            
            # è®¾ç½®é»„è‰²èƒŒæ™¯æ ·å¼
            from openpyxl.styles import PatternFill
            yellow_fill = PatternFill(start_color='FFFF00', end_color='FFFF00', fill_type='solid')
            
            # å¯¹SCMæ•°æ®è¡Œåº”ç”¨é»„è‰²èƒŒæ™¯ï¼ˆæ³¨æ„ï¼šExcelè¡Œç´¢å¼•ä»1å¼€å§‹ï¼Œä¸”æœ‰æ ‡é¢˜è¡Œï¼‰
            for row_idx in scm_indices:
                for col_idx in range(1, len(df.columns) + 1):
                    worksheet.cell(row=row_idx + 2, column=col_idx).fill = yellow_fill
        
        filename = f'ç›®æ ‡è¡¨_{datetime.now().strftime("%Y%m%d_%H%M")}.xlsx'
        
        return output, filename

# --- ä¸»åº”ç”¨ç±» (Main Application) ---
class NewProductAnalysisApp:
    """æ–°å“åˆ†æåº”ç”¨ä¸»ç±»"""
    
    def __init__(self):
        self.file_processor = FileProcessor()
        self.upload_widget = FileUploadWidget()
        self.mapping_processor = MappingProcessor()
        self.sql_processor = SQLProcessor()
        self.filter_processor = DataFilterProcessor()
        self.data_merger = DataMerger()
        self.result_exporter = ResultExporter()
    
    def _inject_custom_css(self):
        """æ³¨å…¥è‡ªå®šä¹‰CSSï¼Œå®ç°å¡ç‰‡å¼å¸ƒå±€å’Œç¾åŒ–"""
        st.markdown(
            """
            <style>
                .card { background-color: #f9fafb; border-radius: 12px; padding: 20px; margin-bottom: 18px; box-shadow: 0 2px 8px rgba(0,0,0,0.06); }
                .card-title { font-size: 16px; font-weight: 700; color: #333; margin-bottom: 12px; }
                .muted { color: #666; font-size: 13px; }
                .primary-btn .st-emotion-cache-7ym5gk { font-size: 16px; padding: 10px 16px; }
            </style>
            """,
            unsafe_allow_html=True,
        )
    
    def render_header(self):
        """æ¸²æŸ“é¡µé¢å¤´éƒ¨"""
        st.set_page_config(page_title="æ–°å“è¿‡ä¼šåˆ†æè¡¨ç”Ÿæˆå·¥å…·", layout="wide")
        st.title("ğŸ” æ–°å“è¿‡ä¼šåˆ†æè¡¨ç”Ÿæˆå·¥å…·")
        st.markdown(
            """
            **æ“ä½œæ­¥éª¤ï¼š** 
            1. ä¸Šä¼ æ˜ å°„å…³ç³»è¡¨ â†’ 
            2. ä¸Šä¼ æ–°å“ç”³æŠ¥æ•°æ® â†’ 
            3. è¿è¡Œç”Ÿæˆ â†’ 
            4. ä¸‹è½½ç»“æœ
            """
        )
        st.divider()
    
    def render_input_section(self):
        """â‘  æ•°æ®ä¸Šä¼ ï¼ˆä¸¤åˆ—å¹¶æ’ï¼Œç§»é™¤SQLå¯è§†é¡¹ï¼‰"""
        st.markdown('<div class="card">', unsafe_allow_html=True)
        st.markdown('<div class="card-title">â‘  æ•°æ®ä¸Šä¼ </div>', unsafe_allow_html=True)
        col1, col2 = st.columns(2)
        with col1:
            st.markdown("**æ˜ å°„å…³ç³»è¡¨**")
            map_file = st.file_uploader("ä¸Šä¼ å®šä¹‰å­—æ®µæ˜ å°„å…³ç³»çš„Excelæ–‡ä»¶", type=["xlsx", "xls"], key="map_uploader_new")
            if map_file:
                with st.spinner("æ­£åœ¨è¯»å–æ˜ å°„è¡¨..."):
                    st.session_state["map_df"] = FileProcessor.read_excel_safe(map_file)
        with col2:
            st.markdown("**æ–°å“ç”³æŠ¥æ•°æ®**")
            scm_file = st.file_uploader("ä¸Šä¼ ä»SCMç³»ç»Ÿå¯¼å‡ºçš„æ–°å“ç”³æŠ¥Excelæ–‡ä»¶", type=["xlsx", "xls"], key="scm_uploader_new")
            if scm_file:
                with st.spinner("æ­£åœ¨è¯»å–æ–°å“æ•°æ®..."):
                    st.session_state["scm_df"] = FileProcessor.read_excel_safe(scm_file)
        # æˆåŠŸæç¤ºï¼ˆè¡Œ+åˆ—ï¼‰
        if st.session_state.get("map_df") is not None:
            df = st.session_state["map_df"]
            st.success(f"âœ… æ˜ å°„å…³ç³»è¡¨å·²åŠ è½½ ({df.shape[0]} è¡Œï¼Œ{df.shape[1]} åˆ—)")
        if st.session_state.get("scm_df") is not None:
            df = st.session_state["scm_df"]
            st.success(f"âœ… æ–°å“ç”³æŠ¥æ•°æ®å·²åŠ è½½ ({df.shape[0]} è¡Œï¼Œ{df.shape[1]} åˆ—)")
        st.markdown('</div>', unsafe_allow_html=True)
    
    def render_action_section(self):
        """â‘¡ æ‰§è¡Œåˆ†æï¼ˆå•ç‹¬å¡ç‰‡ + å¤§æŒ‰é’®ï¼‰"""
        st.markdown('<div class="card">', unsafe_allow_html=True)
        st.markdown('<div class="card-title">â‘¡ æ‰§è¡Œç”Ÿæˆ</div>', unsafe_allow_html=True)
        if st.button("ğŸš€ è¿è¡Œ", type="primary", use_container_width=True):
            self._process_analysis()
        st.markdown('</div>', unsafe_allow_html=True)
    
    def _process_analysis(self):
        """æ ¸å¿ƒå¤„ç†æµç¨‹ï¼ˆSQLåå°é™é»˜åŠ è½½ï¼Œä»…åœ¨å¤±è´¥æ—¶æç¤ºï¼‰"""
        map_df = st.session_state.get("map_df")
        scm_df = st.session_state.get("scm_df")
        if map_df is None or scm_df is None:
            st.error("âŒ è¯·å…ˆä¸Šä¼ æ˜ å°„å…³ç³»è¡¨å’Œæ–°å“ç”³æŠ¥æ•°æ®ï¼")
            return
        try:
            status = st.status("å‡†å¤‡å¼€å§‹ç”Ÿæˆâ€¦", expanded=True)
            # æ­¥éª¤1ï¼šæŸ¥è¯¢å¯¹æ ‡å“æ•°æ®
            status.update(label="ğŸ” æ­£åœ¨ä»æ•°æ®åº“æŸ¥è¯¢å¯¹æ ‡å“æ•°æ®â€¦", state="running")
            sql_path = Path("å¯¹æ ‡å“.sql")
            if not sql_path.exists():
                status.update(label="âŒ åå°SQLæ–‡ä»¶ç¼ºå¤±ï¼Œè¯·è”ç³»ç»´æŠ¤äººå‘˜ã€‚", state="running")
                st.error("âŒ åå°SQLæ–‡ä»¶ç¼ºå¤±ï¼Œè¯·è”ç³»ç»´æŠ¤äººå‘˜ã€‚")
                return
            sql_query = self.sql_processor.read_sql_file(sql_path)
            benchmark_df = self.sql_processor.execute_sql_query(sql_query)
            if benchmark_df.empty:
                st.warning("âš ï¸ å¯¹æ ‡å“æ•°æ®æŸ¥è¯¢ä¸ºç©ºï¼Œç»“æœå°†ä»…åŒ…å«æ–°å“æ•°æ®ã€‚")
            
            # æ­¥éª¤2ï¼šæ˜ å°„ + ç­›é€‰ + åˆå¹¶
            status.update(label="ğŸ§­ æ­£åœ¨è¿›è¡Œæ˜ å°„è½¬æ¢ä¸æ•°æ®åˆå¹¶â€¦", state="running")
            map_scm_df = self.mapping_processor.run_mapping(map_df.copy(), scm_df.copy(), source_type='table2')
            filtered_benchmark_df = (
                self.filter_processor.filter_benchmark_data(benchmark_df.copy(), scm_df.copy())
                if not benchmark_df.empty else pd.DataFrame()
            )
            map_benchmark_df = (
                self.mapping_processor.run_mapping(map_df.copy(), filtered_benchmark_df.copy(), source_type='table3')
                if not filtered_benchmark_df.empty else pd.DataFrame()
            )
            target_df = self.data_merger.merge_and_sort_data(map_scm_df.copy(), map_benchmark_df.copy())
            
            # æ­¥éª¤3ï¼šå¯¼å‡ºå¹¶å®Œæˆ
            status.update(label="ğŸ“¦ æ­£åœ¨ç”ŸæˆExcelæ–‡ä»¶â€¦", state="running")
            scm_indices = list(range(len(map_scm_df)))
            output, filename = self.result_exporter.export_to_excel(target_df, scm_indices)
            st.session_state["result_df"] = target_df
            st.session_state["result_output"] = output
            st.session_state["result_filename"] = filename
            status.update(label="ğŸ‰ ç”Ÿæˆå®Œæˆï¼", state="complete")
            #st.success("ğŸ‰ ç”Ÿæˆå®Œæˆï¼")
        except Exception as e:
            st.error(f"âŒ åˆ†æè¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {e}")
            logger.error(f"åˆ†æå¤„ç†é”™è¯¯: {e}", exc_info=True)
    2
    def render_results_section(self):
        """â‘¢ åˆ†æç»“æœï¼ˆä»…åœ¨æœ‰ç»“æœæ—¶æ˜¾ç¤ºï¼‰"""
        if st.session_state.get("result_df") is None:
            return
        st.markdown('<div class="card">', unsafe_allow_html=True)
        st.markdown('<div class="card-title">â‘¢ ç”Ÿæˆç»“æœ</div>', unsafe_allow_html=True)
        st.success("ç”ŸæˆæˆåŠŸï¼Œä»¥ä¸‹æ˜¯ç»“æœæ‘˜è¦ä¸ä¸‹è½½ï¼š")
        col1, col2 = st.columns(2)
        with col1:
            st.metric("æ€»è®¡è¡Œæ•°", st.session_state["result_df"].shape[0])
        with col2:
            st.metric("æ€»è®¡åˆ—æ•°", st.session_state["result_df"].shape[1])
        st.download_button(
            label="ğŸ“¥ ä¸‹è½½Excelç»“æœæ–‡ä»¶",
            data=st.session_state["result_output"].getvalue(),
            file_name=st.session_state["result_filename"],
            mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
            use_container_width=True,
        )
        with st.expander("ç‚¹å‡»é¢„è§ˆç»“æœæ•°æ®"):
            st.dataframe(st.session_state["result_df"])
        st.markdown('</div>', unsafe_allow_html=True)
    
    def run(self):
        """è¿è¡Œåº”ç”¨"""
        self.render_header()
        self._inject_custom_css()
        self.render_input_section()
        self.render_action_section()
        self.render_results_section()

# --- ä¸»å‡½æ•° ---
def main():
    """åº”ç”¨å…¥å£å‡½æ•°"""
    app = NewProductAnalysisApp()
    app.run()

if __name__ == "__main__":
    main()